{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a31dd2f-7d30-47bd-9320-72007274d381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":white_check_mark: CSV file saved to /Volumes/workspace/default/test/restaurant_customer_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "csv_url = \"https://raw.githubusercontent.com/prasertcbs/basic-dataset/master/Restaurant%20customer%20data.csv\"\n",
    "local_path = \"/Volumes/workspace/default/test/restaurant_customer_data.csv\"\n",
    "response = requests.get(csv_url)\n",
    "with open(local_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(f\":white_check_mark: CSV file saved to {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a50900-3046-4e07-a026-907761e79a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":white_check_mark: Data processed and saved to Delta format in: /Volumes/workspace/default/test/restaurant_customers_delta\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "spark = SparkSession.builder.appName(\"ETL Pipeline\").getOrCreate()\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/Volumes/workspace/default/test/restaurant_customer_data.csv\")\n",
    "df_transformed = df.withColumn(\"birth_year\", when(col(\"birth_year\").rlike(\"^[0-9]+$\"), col(\"birth_year\").cast(IntegerType())).otherwise(None)) \\\n",
    "                   .withColumn(\"weight\", when(col(\"weight\").rlike(\"^[0-9]+(\\\\.[0-9]+)?$\"), col(\"weight\").cast(FloatType())).otherwise(None)) \\\n",
    "                   .withColumn(\"budget\", when(col(\"budget\").rlike(\"^[0-9]+(\\\\.[0-9]+)?$\"), col(\"budget\").cast(FloatType())).otherwise(None)) \\\n",
    "                   .withColumn(\"height\", when(col(\"height\").rlike(\"^[0-9]+(\\\\.[0-9]+)?$\"), col(\"height\").cast(FloatType())).otherwise(None))\n",
    "df_cleaned = df_transformed.na.drop(subset=[\"weight\", \"budget\", \"height\"])\n",
    "silver_table_path = \"/Volumes/workspace/default/test/restaurant_customers_delta\"\n",
    "df_cleaned.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\n",
    "print(\":white_check_mark: Data processed and saved to Delta format in:\", silver_table_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL-Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}